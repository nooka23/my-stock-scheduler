import os
import pandas as pd
import numpy as np
from supabase import create_client, Client
from dotenv import load_dotenv
import json
import time
import io

# 1. ì„¤ì • ë¡œë“œ
load_dotenv('.env.local')
url = os.environ.get("NEXT_PUBLIC_SUPABASE_URL")
key = os.environ.get("SUPABASE_SERVICE_KEY")

if not url or not key:
    print("Error: í‚¤ ì„¤ì • í™•ì¸ í•„ìš”")
    exit()

supabase: Client = create_client(url, key)

print("ğŸš€ JSON íŒŒì¼ RSì§€ìˆ˜ ì—…ë°ì´íŠ¸ ì‹œì‘ (ëŒ€ê³µì‚¬)...")

# ---------------------------------------------------------
# 1. íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
# ---------------------------------------------------------
print("1. ì €ì¥ëœ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘...")
# Storage APIëŠ” í•œ ë²ˆì— ë§ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ê¸° ì–´ë ¤ìš°ë¯€ë¡œ, 
# 'companies' í…Œì´ë¸”(ì´ë¯¸ DBì— ìˆìŒ)ì„ ì´ìš©í•´ì„œ ì½”ë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.
response = supabase.table("companies").select("code, name").range(0, 9999).execute()
target_stocks = response.data

print(f"   - ì´ {len(target_stocks)}ê°œ ì¢…ëª© ëŒ€ìƒ")

# ---------------------------------------------------------
# 2. ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ë©”ëª¨ë¦¬ì— ì ì¬)
# ---------------------------------------------------------
print("2. ëª¨ë“  JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ (ì‹œê°„ì´ ê½¤ ê±¸ë¦½ë‹ˆë‹¤)...")

all_data_frames = []
download_count = 0

for idx, stock in enumerate(target_stocks):
    code = stock['code']
    
    if idx % 100 == 0:
        print(f"   [{idx}/{len(target_stocks)}] ë‹¤ìš´ë¡œë“œ ì§„í–‰ ì¤‘...")

    try:
        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ë©”ëª¨ë¦¬ë¡œ)
        res = supabase.storage.from_("stocks").download(f"{code}.json")
        
        # JSON -> DataFrame ë³€í™˜
        # resëŠ” binary ë°ì´í„°ì´ë¯€ë¡œ decode í•„ìš”
        json_str = res.decode('utf-8')
        df = pd.read_json(io.StringIO(json_str))
        
        # ì½”ë“œ ì»¬ëŸ¼ ì¶”ê°€ (ë‚˜ì¤‘ì— í”¼ë²—íŒ…ì„ ìœ„í•´)
        df['code'] = code
        all_data_frames.append(df)
        download_count += 1
        
    except Exception as e:
        # íŒŒì¼ì´ ì—†ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ íŒ¨ìŠ¤ (ìƒì¥íì§€ ë“±)
        continue

print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {download_count}ê°œ íŒŒì¼ í™•ë³´")

if not all_data_frames:
    print("ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. update_prices_json.pyë¥¼ ë¨¼ì € ì‹¤í–‰í–ˆë‚˜ìš”?")
    exit()

# ---------------------------------------------------------
# 3. ê°€ì¤‘ RS ì§€ìˆ˜ ëŒ€ëŸ‰ ê³„ì‚° (ìˆ˜ì •ë¨)
# ---------------------------------------------------------
print("ğŸ§® 3. ì „ì²´ ì—­ì‚¬ì  ê°€ì¤‘ RS ì§€ìˆ˜ ê³„ì‚° ì¤‘...")

full_df = pd.concat(all_data_frames)
full_df['date'] = pd.to_datetime(full_df['time'])
pivot_df = full_df.pivot(index='date', columns='code', values='close')

# â˜… [ìˆ˜ì •] 4ë¶„ê¸° ê°€ì¤‘ í•©ì‚° ë¡œì§ ì ìš©
price_now = pivot_df
price_3m = pivot_df.shift(63)
price_6m = pivot_df.shift(126)
price_9m = pivot_df.shift(189)
price_12m = pivot_df.shift(252)

# ê° êµ¬ê°„ë³„ ìˆ˜ìµë¥ 
ret_q1 = (price_now - price_3m) / price_3m
ret_q2 = (price_3m - price_6m) / price_6m
ret_q3 = (price_6m - price_9m) / price_9m
ret_q4 = (price_9m - price_12m) / price_12m

# ê°€ì¤‘ í•©ì‚°
weighted_score = (0.4 * ret_q1) + (0.2 * ret_q2) + (0.2 * ret_q3) + (0.2 * ret_q4)

# ë­í‚¹ ì‚°ì •
rs_df = weighted_score.rank(axis=1, pct=True) * 99
rs_df = rs_df.fillna(0).round().astype(int).clip(1, 99)

print("âœ… ê°€ì¤‘ RS ê³„ì‚° ì™„ë£Œ! ì—…ë¡œë“œ ì¤€ë¹„í•©ë‹ˆë‹¤.")

# ---------------------------------------------------------
# 4. íŒŒì¼ë³„ ë³‘í•© ë° ì¬ì—…ë¡œë“œ
# ---------------------------------------------------------
print("ğŸ’¾ 4. ê° íŒŒì¼ì— RS ì¶”ê°€ í›„ ì¬ì—…ë¡œë“œ ì‹œì‘ (ê°€ì¥ ì˜¤ë˜ ê±¸ë¦¼)...")

# RS ë°ì´í„°í”„ë ˆì„ì„ ë‹¤ì‹œ ê¸¸ê²Œ ë³€í™˜ (Stack)
rs_long = rs_df.stack().reset_index()
rs_long.columns = ['date', 'code', 'rs']
# ë‚ ì§œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (ê¸°ì¡´ JSON í¬ë§·ì¸ YYYY-MM-DDì™€ ë§ì¶”ê¸° ìœ„í•´)
rs_long['time_str'] = rs_long['date'].dt.strftime('%Y-%m-%d')

# ê²€ìƒ‰ ì†ë„ë¥¼ ìœ„í•´ { (code, time): rs } í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
# ì´ë ‡ê²Œ í•˜ë©´ ë§¤í•‘ ì†ë„ê°€ ì—„ì²­ ë¹¨ë¼ì§
print("   - ê³ ì† ë§¤í•‘ì„ ìœ„í•œ ì¸ë±ì‹± ì¤‘...")
rs_dict = {}
# to_dict('records')ëŠ” ëŠë¦¬ë¯€ë¡œ zip ì‚¬ìš©
for c, t, r in zip(rs_long['code'], rs_long['time_str'], rs_long['rs']):
    rs_dict[(c, t)] = r

print("   - ì—…ë¡œë“œ ì‹œì‘...")

# ì›ë˜ ë°ì´í„°í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° ì—…ë°ì´íŠ¸
for idx, df in enumerate(all_data_frames):
    code = df['code'].iloc[0] # ì´ ë°ì´í„°í”„ë ˆì„ì˜ ì£¼ì¸ ì½”ë“œ
    
    if idx % 50 == 0:
        print(f"   [{idx}/{len(all_data_frames)}] ì¬ì—…ë¡œë“œ ì¤‘...")

    try:
        # RS ì»¬ëŸ¼ ì¶”ê°€
        # map í•¨ìˆ˜ë¥¼ ì¨ì„œ rs_dictì—ì„œ ì ìˆ˜ë¥¼ ì°¾ì•„ ë„£ìŒ. ì—†ìœ¼ë©´ 0
        df['rs'] = df['time'].map(lambda t: rs_dict.get((code, t), None))
        
        # 'code', 'date' ì„ì‹œ ì»¬ëŸ¼ ì œê±° (ì €ì¥í•  ë• í•„ìš” ì—†ìŒ)
        save_df = df.drop(columns=['code', 'date'], errors='ignore')
        
        # NaN ì²˜ë¦¬ (RS ì—†ëŠ” ì´ˆê¸° ë°ì´í„° ë“±) -> nullë¡œ ë‘ë©´ ì°¨íŠ¸ì—ì„œ ì•ˆ ê·¸ë ¤ì§ (ê¹”ë”)
        # JSON ë³€í™˜
        json_data = save_df.to_json(orient='records')

        # ì¬ì—…ë¡œë“œ (ë®ì–´ì“°ê¸°)
        # 429 ì—ëŸ¬ ë°©ì§€ ë¡œì§ í¬í•¨
        for attempt in range(5):
            try:
                supabase.storage.from_("stocks").upload(
                    file=json_data.encode('utf-8'),
                    path=f"{code}.json",
                    file_options={"content-type": "application/json", "upsert": "true"}
                )
                break
            except Exception as err:
                if "429" in str(err):
                    time.sleep(2 * (attempt + 1))
                elif attempt == 4:
                    print(f"      âŒ {code} ì—…ë¡œë“œ ì‹¤íŒ¨: {err}")
                else:
                    time.sleep(0.5)
        
        # ë„ˆë¬´ ë¹ ë¥´ë©´ ë¡œì»¬ PC ë„¤íŠ¸ì›Œí¬ë„ ë§‰í ìˆ˜ ìˆìœ¼ë‹ˆ ë¯¸ì„¸í•œ ë”œë ˆì´
        time.sleep(0.02)

    except Exception as e:
        print(f"      âŒ {code} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")

print("\nğŸ‰ ëª¨ë“  ê³¼ê±° ë°ì´í„° RS ì—…ë°ì´íŠ¸ ì™„ë£Œ!")