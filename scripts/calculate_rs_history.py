import os
import pandas as pd
import numpy as np
from supabase import create_client, Client
from dotenv import load_dotenv
import time

# 1. ì„¤ì • ë¡œë“œ
load_dotenv('.env.local')
url = os.environ.get("NEXT_PUBLIC_SUPABASE_URL")
key = os.environ.get("SUPABASE_SERVICE_KEY")

if not url or not key:
    print("Error: .env.local íŒŒì¼ ì„¤ì • í™•ì¸ í•„ìš”")
    exit()

supabase: Client = create_client(url, key)

print("â³ 1. ì „ì²´ ì£¼ê°€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ (ê°€ì¤‘ RS ê³„ì‚°ìš©)...")

# ì „ì²´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ í•¨ìˆ˜
def fetch_all_data():
    all_data = []
    start = 0
    batch_size = 2000
    
    # 12ê°œì›” ì „ ë°ì´í„°ë¥¼ ê³„ì‚°í•´ì•¼ í•˜ë¯€ë¡œ 2024ë…„ 1ì›”ë¶€í„° ê°€ì ¸ì˜´
    while True:
        print(f"   - {start} ~ {start + batch_size} í–‰ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        
        response = supabase.table("stock_prices") \
            .select("*") \
            .gte("date_str", "2024-01-01") \
            .lte("date_str", "2025-11-28") \
            .range(start, start + batch_size - 1) \
            .execute()
        
        data = response.data
        if not data:
            break
            
        all_data.extend(data)
        start += batch_size
        
        if len(data) < batch_size:
            break
            
    return pd.DataFrame(all_data)

# ë°ì´í„°í”„ë ˆì„ ìƒì„±
df = fetch_all_data()
print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: ì´ {len(df)}ê°œ í–‰")

if df.empty:
    print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# ---------------------------------------------------------
# 2. ê°€ì¤‘ RS ì§€ìˆ˜(Weighted RS) ì •ë°€ ê³„ì‚°
# ---------------------------------------------------------
print("ğŸ§® 2. 4ë¶„ê¸° ê°€ì¤‘ RS ì§€ìˆ˜ ê³„ì‚° ì¤‘...")

df['date'] = pd.to_datetime(df['date_str'])
df = df.sort_values(['code', 'date'])

# í”¼ë²— í…Œì´ë¸” (í–‰: ë‚ ì§œ, ì—´: ì¢…ëª©, ê°’: ì¢…ê°€)
pivot_df = df.pivot(index='date', columns='code', values='close')

# ê±°ë˜ì¼ ê¸°ì¤€ (ëŒ€ëµ 1ë‹¬ = 21ì¼, 3ë‹¬ = 63ì¼)
# Q1: ìµœê·¼ 3ê°œì›” (0~3ê°œì›”)
# Q2: 4~6ê°œì›” ì „ (3~6ê°œì›”)
# Q3: 7~9ê°œì›” ì „ (6~9ê°œì›”)
# Q4: 10~12ê°œì›” ì „ (9~12ê°œì›”)

# ê° ì‹œì ì˜ ê°€ê²© êµ¬í•˜ê¸° (shift ì‚¬ìš©)
price_now = pivot_df
price_3m = pivot_df.shift(63)  # 3ê°œì›” ì „
price_6m = pivot_df.shift(126) # 6ê°œì›” ì „
price_9m = pivot_df.shift(189) # 9ê°œì›” ì „
price_12m = pivot_df.shift(252) # 12ê°œì›” ì „

# ê° ë¶„ê¸°ë³„ ìˆ˜ìµë¥ (Return) ê³„ì‚°
# Q1 Return: (í˜„ì¬ - 3ê°œì›”ì „) / 3ê°œì›”ì „
ret_q1 = (price_now - price_3m) / price_3m

# Q2 Return: (3ê°œì›”ì „ - 6ê°œì›”ì „) / 6ê°œì›”ì „
ret_q2 = (price_3m - price_6m) / price_6m

# Q3 Return: (6ê°œì›”ì „ - 9ê°œì›”ì „) / 9ê°œì›”ì „
ret_q3 = (price_6m - price_9m) / price_9m

# Q4 Return: (9ê°œì›”ì „ - 12ê°œì›”ì „) / 12ê°œì›”ì „
ret_q4 = (price_9m - price_12m) / price_12m

# ê°€ì¤‘ í•©ì‚° ì ìˆ˜ ê³„ì‚° (Weighted Score)
# ê³µì‹: (0.4 * Q1) + (0.2 * Q2) + (0.2 * Q3) + (0.2 * Q4)
weighted_score = (0.4 * ret_q1) + (0.2 * ret_q2) + (0.2 * ret_q3) + (0.2 * ret_q4)

# 2025ë…„ ë°ì´í„°ë§Œ íƒ€ê²ŸíŒ…
target_score = weighted_score.loc['2025-01-01':'2025-11-28']

# ë­í‚¹ ì‚°ì • (1~99ì )
# ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ 1ë“± -> ë°±ë¶„ìœ„ -> 99ì 
rs_df = target_score.rank(axis=1, pct=True) * 99
rs_df = rs_df.round().fillna(0).astype(int)
rs_df = rs_df.clip(1, 99)

print("âœ… ê°€ì¤‘ RS ê³„ì‚° ì™„ë£Œ!")

# ---------------------------------------------------------
# 3. DBì— ê²°ê³¼ ì—…ë¡œë“œ (ë™ì¼)
# ---------------------------------------------------------
print("ğŸ’¾ 3. DB ì—…ë°ì´íŠ¸ ì‹œì‘...")

# RS ë°ì´í„° ë³€í˜• (Long Format)
upload_data = rs_df.stack().reset_index()
upload_data.columns = ['date', 'code', 'rs_rating']
upload_data['date_str'] = upload_data['date'].dt.strftime('%Y-%m-%d')

# ì›ë³¸ ë°ì´í„° ì¤€ë¹„
original_2025 = df[df['date'] >= '2025-01-01'].copy()
original_2025['date_str'] = original_2025['date'].dt.strftime('%Y-%m-%d')

# ê¸°ì¡´ rs_rating ì œê±° (ì¶©ëŒ ë°©ì§€)
if 'rs_rating' in original_2025.columns:
    original_2025 = original_2025.drop(columns=['rs_rating'])

# ë³‘í•©
merged_df = pd.merge(original_2025, upload_data[['code', 'date_str', 'rs_rating']], on=['code', 'date_str'], how='left')
merged_df['rs_rating'] = merged_df['rs_rating'].fillna(0).astype(int)

# ë¦¬ìŠ¤íŠ¸ ë³€í™˜
final_records = []
for _, row in merged_df.iterrows():
    final_records.append({
        "code": row['code'],
        "date_str": row['date_str'],
        "open": row['open'],
        "high": row['high'],
        "low": row['low'],
        "close": row['close'],
        "volume": row['volume'],
        "rs_rating": row['rs_rating']
    })

# ì—…ë¡œë“œ ì‹¤í–‰
total_records = len(final_records)
print(f"   - ì´ ì—…ë°ì´íŠ¸ í•  ë°ì´í„°: {total_records}ê±´")

chunk_size = 2000
for i in range(0, total_records, chunk_size):
    chunk = final_records[i:i + chunk_size]
    try:
        supabase.table("stock_prices").upsert(chunk, on_conflict="code, date_str").execute()
        print(f"     âœ… {i} ~ {i+len(chunk)} ì™„ë£Œ")
    except Exception as e:
        print(f"     âŒ ì—ëŸ¬: {e}")

print("ğŸ‰ ê°€ì¤‘ RS(Weighted RS) íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")