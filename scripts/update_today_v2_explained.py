# ======================================================================================
# ğŸ“˜ ì´ˆë³´ìë¥¼ ìœ„í•œ ì½”ë“œ ì„¤ëª…ì„œ: ì£¼ì‹ ë°ì´í„° ì¼ì¼ ì—…ë°ì´íŠ¸ (update_today_v2.py)
# ======================================================================================
# ì´ í”„ë¡œê·¸ë¨ì€ ë§¤ì¼ë§¤ì¼ ìƒˆë¡œìš´ ì£¼ê°€ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤(Supabase)ì— ì €ì¥í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
# íŠ¹íˆ 'ìˆ˜ì •ì£¼ê°€'(ì•¡ë©´ë¶„í•  ë“±ìœ¼ë¡œ ê³¼ê±° ì£¼ê°€ê°€ ë³€í•˜ëŠ” í˜„ìƒ)ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•´ì„œ ì²˜ë¦¬í•˜ëŠ” ë˜‘ë˜‘í•œ ê¸°ëŠ¥ì´ ìˆìŠµë‹ˆë‹¤.
#
# ì½”ë“œëŠ” ìœ„ì—ì„œ ì•„ë˜ë¡œ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. í•œ ì¤„ì”© ì²œì²œíˆ ì½ì–´ë³´ì„¸ìš”! ğŸ˜Š
# ======================================================================================

# 1ï¸âƒ£ í•„ìš”í•œ ë„êµ¬(ë¼ì´ë¸ŒëŸ¬ë¦¬)ë“¤ì„ ê°€ì ¸ì˜¤ëŠ” ë‹¨ê³„
# ë§ˆì¹˜ ìš”ë¦¬í•˜ê¸° ì „ì— ì¬ë£Œì™€ ë„êµ¬ë¥¼ ì¤€ë¹„í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.
import os                                   # ìš´ì˜ì²´ì œ(Windows/Mac) ê¸°ëŠ¥ ì‚¬ìš© (ì˜ˆ: í™˜ê²½ë³€ìˆ˜ ì½ê¸°)
import FinanceDataReader as fdr             # í•œêµ­/ë¯¸êµ­ ì£¼ì‹ ê°€ê²©ì„ ê°€ì ¸ì˜¤ëŠ” ì•„ì£¼ ìœ ìš©í•œ ë„êµ¬
import pandas as pd                         # ì—‘ì…€ì²˜ëŸ¼ í‘œ(Table) í˜•íƒœì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë„êµ¬
from supabase import create_client, Client  # Supabase ë°ì´í„°ë² ì´ìŠ¤ì™€ ëŒ€í™”í•˜ê¸° ìœ„í•œ ë„êµ¬
from dotenv import load_dotenv              # .env íŒŒì¼ì— ìˆ¨ê²¨ë‘” ë¹„ë°€í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë„êµ¬
import time                                 # ì‹œê°„ ê´€ë ¨ ê¸°ëŠ¥ (ì˜ˆ: ì ê¹ ë©ˆì¶”ê¸°)
from datetime import datetime, timedelta    # ë‚ ì§œì™€ ì‹œê°„ì„ ê³„ì‚°í•˜ëŠ” ë„êµ¬

# 2ï¸âƒ£ ë³´ì•ˆ ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ)
# ë¹„ë°€ë²ˆí˜¸ ê°™ì€ ì¤‘ìš”í•œ ì •ë³´ëŠ” ì½”ë“œì— ì§ì ‘ ì ì§€ ì•Šê³  '.env.local'ì´ë¼ëŠ” ë³„ë„ íŒŒì¼ì— ìˆ¨ê²¨ë‘¡ë‹ˆë‹¤.
# ì´ í•¨ìˆ˜ê°€ ê·¸ ë¹„ë°€ ê¸ˆê³ (.env.local)ë¥¼ ì—½ë‹ˆë‹¤.
load_dotenv('.env.local')

# ê¸ˆê³ ì—ì„œ Supabase ì£¼ì†Œì™€ ì—´ì‡ (Key)ë¥¼ êº¼ëƒ…ë‹ˆë‹¤.
url = os.environ.get("NEXT_PUBLIC_SUPABASE_URL")
key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY")

# ë§Œì•½ ì—´ì‡ ê°€ ì—†ìœ¼ë©´ "ì˜¤ë¥˜"ë¼ê³  ì•Œë ¤ì£¼ê³  í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.
if not url or not key:
    print("âŒ í™˜ê²½ë³€ìˆ˜ ì˜¤ë¥˜: .env.local íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”!")
    exit()

# 3ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
# ì´ì œ Supabase ë°ì´í„°ë² ì´ìŠ¤ì— ì ‘ì†í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.
# 'supabase' ë³€ìˆ˜ë¥¼ í†µí•´ ì•ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë„£ê±°ë‚˜ ëº„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
supabase: Client = create_client(url, key)

print("ğŸš€ ë°ì¼ë¦¬ ì—…ë°ì´íŠ¸ V2 (ìˆ˜ì •ì£¼ê°€ ìë™ ë³´ì •) ì‹œì‘!")

# 4ï¸âƒ£ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
# í•œêµ­ê±°ë˜ì†Œ(KRX)ì— ìƒì¥ëœ ëª¨ë“  ì¢…ëª© ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
df_krx = fdr.StockListing('KRX')

# 5ï¸âƒ£ ë¶ˆí•„ìš”í•œ ì¢…ëª© ê±¸ëŸ¬ë‚´ê¸° (í•„í„°ë§)
# ì£¼ì‹ ë¶„ì„ì— ë°©í•´ë˜ëŠ” 'ìŠ¤íŒ©(SPAC)', 'ETN', 'ETF'ë‚˜ 'ìš°ì„ ì£¼(ì´ë¦„ ëì´ 'ìš°'ë¡œ ëë‚¨)'ë¥¼ ëºë‹ˆë‹¤.
# ~ ê¸°í˜¸ëŠ” 'ë°˜ëŒ€(NOT)'ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¦‰, ìŠ¤íŒ©ì´ 'ì•„ë‹Œ' ê²ƒë§Œ ë‚¨ê¹ë‹ˆë‹¤.
filter_mask = (
    ~df_krx['Name'].str.contains('ìŠ¤íŒ©|ETN|ETF', case=False) & 
    ~df_krx['Name'].str.endswith(('ìš°', 'ìš°B', 'ìš°C'))
)

# í•„ìš”í•œ ì •ë³´(ì¢…ëª©ì½”ë“œ, ì´ë¦„, ì‹œì¥êµ¬ë¶„, ì‹œê°€ì´ì•¡)ë§Œ ë½‘ì•„ëƒ…ë‹ˆë‹¤.
# to_dict('records')ëŠ” í‘œ(DataFrame) ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ[{'Code': '...', ...}, ...]ë¡œ ë³€í™˜í•´ì¤ë‹ˆë‹¤.
# ì´ë ‡ê²Œ í•˜ë©´ ë°˜ë³µë¬¸(forë¬¸)ì„ ëŒë¦¬ê¸° í¸í•´ì§‘ë‹ˆë‹¤.
target_stocks_df = df_krx[filter_mask][['Code', 'Name', 'Market', 'Marcap']]
target_stocks = target_stocks_df.to_dict('records')

print(f"âœ… ëŒ€ìƒ ì¢…ëª©: {len(target_stocks)}ê°œ")

# 6ï¸âƒ£ íšŒì‚¬ ì •ë³´(Companies) í…Œì´ë¸” ì—…ë°ì´íŠ¸
# ì¢…ëª© ì½”ë“œëŠ” ê·¸ëŒ€ë¡œì¸ë° íšŒì‚¬ ì´ë¦„ì´ ë°”ë€Œê±°ë‚˜, ì‹œê°€ì´ì•¡ì´ ë³€í–ˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì •ë³´ë¥¼ ìµœì‹ í™”í•©ë‹ˆë‹¤.
print("   Companies í…Œì´ë¸” ë™ê¸°í™” ì¤‘...")

company_upload_list = []
for stock in target_stocks:
    company_upload_list.append({
        "code": str(stock['Code']),           # ì¢…ëª©ì½”ë“œ (ë¬¸ìì—´ë¡œ ë³€í™˜)
        "name": stock['Name'],                # íšŒì‚¬ëª…
        "market": stock['Market'],            # ì‹œì¥ (KOSPI, KOSDAQ ë“±)
        # ì‹œê°€ì´ì•¡ì´ ë¹„ì–´ìˆìœ¼ë©´(NaN) 0ìœ¼ë¡œ ì²˜ë¦¬
        "marcap": float(stock['Marcap']) if not pd.isna(stock['Marcap']) else 0
    })

# ğŸ’¡ ëŒ€ëŸ‰ ë°ì´í„° ì—…ë¡œë“œ (ì²­í¬ ì²˜ë¦¬)
# í•œ ë²ˆì— ìˆ˜ì²œ ê°œë¥¼ ë³´ë‚´ë©´ ì¸í„°ë„·ì´ ëŠê¸°ê±°ë‚˜ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ê·¸ë˜ì„œ 1000ê°œì”© ìª¼ê°œì„œ(chunk) ë³´ëƒ…ë‹ˆë‹¤.
# upsert: "Update" + "Insert"ì˜ í•©ì„±ì–´. ìˆìœ¼ë©´ ìˆ˜ì •í•˜ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ë„£ìœ¼ë¼ëŠ” ëœ»!
for i in range(0, len(company_upload_list), 1000):
    chunk = company_upload_list[i:i+1000]
    supabase.table("companies").upsert(chunk).execute()

# 7ï¸âƒ£ ì£¼ê°€ ì—…ë°ì´íŠ¸ ì¤€ë¹„
# ë¹„êµë¥¼ ìœ„í•´ '10ì¼ ì „' ë‚ ì§œë¥¼ êµ¬í•©ë‹ˆë‹¤. (ì£¼ë§/íœ´ì¼ì„ ê³ ë ¤í•´ì„œ ë„‰ë„‰í•˜ê²Œ ì¡ìŒ)
CHECK_START_DATE = (datetime.now() - timedelta(days=10)).strftime('%Y-%m-%d')
# ë§Œì•½ ë°ì´í„°ë¥¼ ì™„ì „íˆ ìƒˆë¡œ ë°›ì•„ì•¼ í•  ë•Œ ì“¸ ì‹œì‘ ë‚ ì§œ (2015ë…„ë¶€í„°)
FULL_START_DATE = '2015-01-01'

success_count = 0  # ì„±ê³µí•œ ì¢…ëª© ìˆ˜ ì„¸ê¸°
updated_count = 0  # ìˆ˜ì •ì£¼ê°€ë¡œ ì¸í•´ ì „ì²´ ë‹¤ì‹œ ë°›ì€ ì¢…ëª© ìˆ˜ ì„¸ê¸°

# 8ï¸âƒ£ ê°œë³„ ì¢…ëª© ë°˜ë³µë¬¸ (ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„!)
# enumerateëŠ” ë²ˆí˜¸(idx)ì™€ ë°ì´í„°(stock)ë¥¼ ê°™ì´ ì¤ë‹ˆë‹¤. (0ë²ˆ ì‚¼ì„±ì „ì, 1ë²ˆ SKí•˜ì´ë‹‰ìŠ¤...)
for idx, stock in enumerate(target_stocks):
    code = str(stock['Code'])
    name = stock['Name']
    
    # 50ë²ˆì§¸ ì¢…ëª©ë§ˆë‹¤ ì§„í–‰ ìƒí™©ì„ ì¶œë ¥í•´ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤. (ë„ˆë¬´ ì¡°ìš©í•˜ë©´ ë©ˆì¶˜ ì¤„ ì•„ë‹ˆê¹Œìš”)
    if idx % 50 == 0:
        print(f"[{idx+1}/{len(target_stocks)}] {name}({code}) ì§„í–‰ ì¤‘...")

    try: # try: ì—ëŸ¬ê°€ ë‚˜ë„ í”„ë¡œê·¸ë¨ì´ ë©ˆì¶”ì§€ ì•Šê²Œ ê°ì‹¸ì¤ë‹ˆë‹¤.
        
        # [ë‹¨ê³„ A] ë‚´ ë°ì´í„°ë² ì´ìŠ¤(Supabase)ì— ì €ì¥ëœ ê°€ì¥ ìµœì‹  ë‚ ì§œì™€ ê°€ê²© í™•ì¸
        # "daily_prices_v2 í…Œì´ë¸”ì—ì„œ codeê°€ ì´ê±°ì¸ ê²ƒ ì¤‘, ë‚ ì§œ(date) ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ 1ê°œë§Œ ê°€ì ¸ì™€ë¼"
        res = supabase.table('daily_prices_v2') \
            .select('date, close') \
            .eq('code', code) \
            .order('date', desc=True) \
            .limit(1) \
            .execute()
            
        # ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ê°’ì„ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ None(ì—†ìŒ)
        db_last_data = res.data[0] if res.data else None
        
        # [ë‹¨ê³„ B] ìµœì‹  ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (FinanceDataReader ì´ìš©)
        # CHECK_START_DATE(10ì¼ ì „) ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        df_recent = fdr.DataReader(f'KRX:{code}', CHECK_START_DATE)
        
        if df_recent.empty: # ë°ì´í„°ê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´ ë‹¤ìŒ ì¢…ëª©ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.
            continue

        need_full_reload = False # "ì „ì²´ ì¬ì ì¬ê°€ í•„ìš”í•œê°€?" ìƒíƒœ ë³€ìˆ˜ (ê¸°ë³¸ê°’: ì•„ë‹ˆì˜¤) 
        
        # [ë‹¨ê³„ C] ìˆ˜ì •ì£¼ê°€ ê°ì§€ ë¡œì§ (í•µì‹¬! â­)
        if db_last_data:
            db_date = db_last_data['date']       # ë‚´ DBì— ì €ì¥ëœ ë§ˆì§€ë§‰ ë‚ ì§œ
            db_close = float(db_last_data['close']) # ë‚´ DBì— ì €ì¥ëœ ë§ˆì§€ë§‰ ì¢…ê°€
            
            # ìƒˆë¡œ ê°€ì ¸ì˜¨ ë°ì´í„°(df_recent)ì— ë‚´ DB ë§ˆì§€ë§‰ ë‚ ì§œê°€ ìˆëŠ”ì§€ í™•ì¸
            if db_date in df_recent.index:
                # FDRì—ì„œ ê°€ì ¸ì˜¨ ê·¸ ë‚ ì§œì˜ ì¢…ê°€
                fdr_close = float(df_recent.loc[db_date]['Close'])
                
                # ğŸ’¡ ë¹„êµ! ë‚´ DB ê°€ê²©ê³¼ ìƒˆë¡œ ì¡°íšŒí•œ ê°€ê²©ì´ ë‹¤ë¥¸ê°€?
                # 1% ì´ìƒ ì°¨ì´ê°€ ë‚˜ë©´ ì•¡ë©´ë¶„í•  ë“±ìœ¼ë¡œ ê³¼ê±° ì£¼ê°€ê°€ ìˆ˜ì •ëœ ê²ƒìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.
                # (ì»´í“¨í„°ëŠ” ì†Œìˆ˜ì  ê³„ì‚°ì´ ì™„ë²½í•˜ì§€ ì•Šì•„ì„œ == ëŒ€ì‹  1% ì°¨ì´ë¡œ ë¹„êµí•˜ëŠ”ê²Œ ì•ˆì „í•©ë‹ˆë‹¤)
                if abs(fdr_close - db_close) / db_close > 0.01:
                    print(f"   ğŸ”„ [ìˆ˜ì •ì£¼ê°€ ê°ì§€] {name}: DBê°€ê²©({db_close}) != FDRê°€ê²©({fdr_close}). ì „ì²´ ë‹¤ì‹œ ë°›ìŠµë‹ˆë‹¤...")
                    need_full_reload = True
        else:
            # DBì— ì•„ë¬´ ë°ì´í„°ë„ ì—†ìœ¼ë©´ ë‹¹ì—°íˆ ì²˜ìŒë¶€í„° ë‹¤ ë°›ì•„ì•¼ê² ì£ ?
            print(f"   âœ¨ [ì‹ ê·œ] {name}: ë°ì´í„°ê°€ ì—†ì–´ì„œ 2015ë…„ë¶€í„° ë‹¤ ë°›ìŠµë‹ˆë‹¤...")
            need_full_reload = True

        # [ë‹¨ê³„ D] ë°ì´í„° ì €ì¥í•˜ê¸°
        if need_full_reload:
            # [ê²½ë¡œ 1] ì „ì²´ ì¬ì ì¬ (ìˆ˜ì •ì£¼ê°€ ë°œìƒ or ì‹ ê·œ ì¢…ëª©)
            updated_count += 1
            
            # 2015ë…„ë¶€í„° ì „ì²´ ë°ì´í„° ë‹¤ì‹œ ìš”ì²­
            df_full = fdr.DataReader(f'KRX:{code}', FULL_START_DATE)
            if df_full.empty: continue
            
            # DBì— ë„£ì„ í˜•íƒœë¡œ ë³€í™˜
            upload_list = []
            for d, r in df_full.iterrows():
                upload_list.append({
                    "code": code,
                    "date": d.strftime('%Y-%m-%d'), # ë‚ ì§œë¥¼ ë¬¸ìì—´ë¡œ (YYYY-MM-DD)
                    "open": int(r['Open']),
                    "high": int(r['High']),
                    "low": int(r['Low']),
                    "close": int(r['Close']),
                    "volume": int(r['Volume']),
                    "change": float(r['Change']) if not pd.isna(r['Change']) else 0.0
                })
            
            # ì—­ì‹œ 1000ê°œì”© ìª¼ê°œì„œ ì—…ë¡œë“œ (upsertê°€ ë®ì–´ì“°ê¸° í•´ì¤ë‹ˆë‹¤)
            for i in range(0, len(upload_list), 1000):
                chunk = upload_list[i:i+1000]
                supabase.table("daily_prices_v2").upsert(chunk, on_conflict="code, date").execute()
                
        else:
            # [ê²½ë¡œ 2] ì¼ë°˜ ëª¨ë“œ (ìµœì‹  ë°ì´í„°ë§Œ ì¶”ê°€)
            if db_last_data:
                # DB ë§ˆì§€ë§‰ ë‚ ì§œë³´ë‹¤ 'ì´í›„'ì¸ ë‚ ì§œì˜ ë°ì´í„°ë§Œ ê³¨ë¼ëƒ…ë‹ˆë‹¤.
                last_db_date = datetime.strptime(db_last_data['date'], '%Y-%m-%d')
                df_new = df_recent[df_recent.index > last_db_date]
            else:
                df_new = df_recent # (ì´ ê²½ìš°ëŠ” ê±°ì˜ ì—†ì§€ë§Œ ì•ˆì „ì¥ì¹˜)

            if df_new.empty:
                # ì¶”ê°€í•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ íŒ¨ìŠ¤ (ì´ë¯¸ ìµœì‹  ìƒíƒœ)
                continue
                
            upload_list = []
            for d, r in df_new.iterrows():
                upload_list.append({
                    "code": code,
                    "date": d.strftime('%Y-%m-%d'),
                    "open": int(r['Open']),
                    "high": int(r['High']),
                    "low": int(r['Low']),
                    "close": int(r['Close']),
                    "volume": int(r['Volume']),
                    "change": float(r['Change']) if not pd.isna(r['Change']) else 0.0
                })
            
            # ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì—…ë¡œë“œ
            if upload_list:
                supabase.table("daily_prices_v2").upsert(upload_list, on_conflict="code, date").execute()
                
        success_count += 1

    except Exception as e:
        # ì—ëŸ¬ê°€ ë‚˜ë©´ ì—¬ê¸°ì„œ ì¡ìŠµë‹ˆë‹¤. (í”„ë¡œê·¸ë¨ì´ ë©ˆì¶”ì§€ ì•Šë„ë¡)
        print(f"   âŒ ì—ëŸ¬ ë°œìƒ {name}: {e}")
        time.sleep(1) # ì—ëŸ¬ë‚˜ë©´ 1ì´ˆ ì‰¬ì—ˆë‹¤ê°€ ë‹¤ì‹œ ì¹¨ì°©í•˜ê²Œ ë‹¤ìŒ ì¢…ëª©ìœ¼ë¡œ

# 9ï¸âƒ£ ë§ˆë¬´ë¦¬ ì¸ì‚¬
print(f"\nğŸ‰ ì—…ë°ì´íŠ¸ ì™„ë£Œ! (ì„±ê³µ: {success_count}ê°œ, ìˆ˜ì •ì£¼ê°€ ë³´ì •: {updated_count}ê°œ)")
